{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgUhLXbkmp8M",
        "colab_type": "text"
      },
      "source": [
        "It's better to upload dataset to Google Drive and mount it to colab. Direct uploading to Colab is too slow and takes too much memory on your PC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39jCs768-0cj",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive to Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyC31dnolAMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc-R1kSB-Rai",
        "colab_type": "text"
      },
      "source": [
        "Uncomment in case you are going to train a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuCrOV3fOfXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!mkdir -p \"/content/data/American/spectrograms\"\n",
        "#!mkdir -p \"/content/data/British/spectrograms\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snh4Darl-fGS",
        "colab_type": "text"
      },
      "source": [
        "Unzips data from Google Drive directly into Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tZB7tO1lsRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip \"/content/drive/My Drive/Datasets/Accent Classifier/spectrograms/spectrograms_amer.zip\" -d /content/data/American/spectrograms\n",
        "#!unzip \"/content/drive/My Drive/Datasets/Accent Classifier/spectrograms/spectrograms_brit.zip\" -d /content/data/British/spectrograms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFwoW97v_KY3",
        "colab_type": "text"
      },
      "source": [
        "Declaration of a neural network wrapper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaN7Q4UkGzZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet50\n",
        "import cv2\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import pathlib\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "NETWORK_INPUT_SIZE = (224, 224)\n",
        "\n",
        "\n",
        "class ConvolutionalNetwork():\n",
        "    def __init__(self, device=\"cpu\"):\n",
        "        \"\"\"\n",
        "        Device can be \"cuda\" or \"cpu\". The latter is the default.\n",
        "        \"\"\"\n",
        "        self.__model = resnet50(pretrained=True)\n",
        "        self.__device = device\n",
        "        self.__batch_size = 5\n",
        "\n",
        "        for param in self.__model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Transfer learning itself. Replace the outer layer with 2 outputs only\n",
        "        num_ftrs = self.__model.fc.in_features\n",
        "        self.__model.fc = torch.nn.Linear(num_ftrs, 2)\n",
        "        self.__model.to(self.__device)\n",
        "\n",
        "    def train_model(self, filenames, labels, test_size=0.2, batch_size=5, epochs=50):\n",
        "        \"\"\"\n",
        "        Train the neural network. This class is needed to encapsulate all the tricky and messy parts.\n",
        "        :param test_size: proportion of test dataset to all files\n",
        "        :param train_filenames: absolute paths to spectrograms\n",
        "        :param train_labels: labels to each file\n",
        "        :param batch_size: quantity of images in one batch\n",
        "        \"\"\"\n",
        "        self.__batch_size = batch_size\n",
        "        self.__epochs = epochs\n",
        "\n",
        "        train_filenames, test_filenames, train_labels, test_labels = train_test_split(filenames, labels,\n",
        "                                                                                      test_size=test_size, shuffle=True)\n",
        "\n",
        "        train_dataset = SpectrogramDataset(train_filenames, train_labels)\n",
        "        train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=self.__batch_size)\n",
        "        test_dataset = SpectrogramDataset(test_filenames, test_labels)\n",
        "        test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=self.__batch_size)\n",
        "\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.__model.parameters(), lr=0.0005)\n",
        "\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "                inputs = inputs.to(torch.device(self.__device))\n",
        "                labels = labels.to(torch.device(self.__device))\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = self.__model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            self.__run_test_on_epoch(epoch, test_dataloader)\n",
        "        self.__model.eval()\n",
        "\n",
        "    def __run_test_on_epoch(self, epoch, test_loader):\n",
        "        self.__model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_accuracy = []\n",
        "            test_real = []\n",
        "            for batch_x, batch_y in tqdm(test_loader):\n",
        "                outputs = self.__model(batch_x.to(self.__device)).detach().cpu().numpy()\n",
        "                test_accuracy.append(outputs)\n",
        "                test_real.append(batch_y.detach().cpu().numpy())\n",
        "            print(\"\\nEpoch\", epoch + 1, \"test accuracy\",\n",
        "                  accuracy_score(np.hstack(test_real), np.argmax(np.vstack(test_accuracy), axis=1)))\n",
        "        self.__model.train()\n",
        "\n",
        "    def predict(self, filenames):\n",
        "        \"\"\"\n",
        "        Predicts each class probability and return the average result\n",
        "        :return np.ndarray with [m, 2] shape, where m is the length of filenames parameter\n",
        "        \"\"\"\n",
        "        test_dataset = SpectrogramDataset(filenames, np.zeros(len(filenames)))\n",
        "        test_dataloader = DataLoader(test_dataset, batch_size=self.__batch_size)\n",
        "\n",
        "        outputs = []\n",
        "        with torch.no_grad():\n",
        "            for batch_x, batch_y in test_dataloader:\n",
        "                prediction = self.__model(batch_x.to(self.__device)).detach().cpu().numpy()\n",
        "                outputs.append(prediction)\n",
        "\n",
        "        return np.vstack(outputs)\n",
        "\n",
        "\n",
        "    def save_weights(self, path):\n",
        "        torch.save(self.__model.state_dict(), path)\n",
        "\n",
        "    def load_weights(self, path, device=\"cpu\"):\n",
        "        self.__model.load_state_dict(torch.load(path), map_location=torch.device(device))\n",
        "        self.__model.eval()\n",
        "\n",
        "    def deep_save(self, path):\n",
        "        \"\"\"\n",
        "        Saves the whole model, i.e. paths, weights, criterions, optimizers, etc.\n",
        "        \"\"\"\n",
        "        torch.save(self.__model, path)\n",
        "\n",
        "    def deep_load(self, path, device=\"cpu\"):\n",
        "        \"\"\"\n",
        "        Loads a deep saved model.\n",
        "        \"\"\"\n",
        "        self.__model = torch.load(path, map_location=torch.device('cpu'))\n",
        "        self.__model.eval()\n",
        "    \n",
        "    def get_model(self):\n",
        "        return self.__model\n",
        "\n",
        "\n",
        "class SpectrogramDataset(Dataset):\n",
        "    def __init__(self, absolute_filenames, labels):\n",
        "        \"\"\"\n",
        "        IMPORTANT: ABSOLUTE paths to files is required\n",
        "        :param absolute_filenames:\n",
        "        :param labels:\n",
        "        \"\"\"\n",
        "        self.__filenames = absolute_filenames\n",
        "        self.__labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.__filenames)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        filename = self.__filenames[item]\n",
        "        label = self.__labels[item]\n",
        "\n",
        "        image = cv2.imread(str(filename))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = resize(image, NETWORK_INPUT_SIZE)\n",
        "        image = add_pad(image, NETWORK_INPUT_SIZE)\n",
        "\n",
        "        image = torch.tensor(image, dtype=torch.float).permute(2, 0, 1) / 255.\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def resize(img, shape):\n",
        "    scale = min(shape[0] * 1.0 / img.shape[0], shape[1] * 1.0 / img.shape[1])\n",
        "    if scale != 1:\n",
        "        img = cv2.resize(img, dsize=None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def add_pad(img, shape):\n",
        "    \"\"\"\n",
        "    Adds padding to make the image square\n",
        "    \"\"\"\n",
        "    color_pick = img[0][0]\n",
        "    padded_img = color_pick * np.ones(shape + img.shape[2:3], dtype=np.uint8)\n",
        "    x_offset = int((padded_img.shape[0] - img.shape[0]) / 2)\n",
        "    y_offset = int((padded_img.shape[1] - img.shape[1]) / 2)\n",
        "    padded_img[x_offset:x_offset + img.shape[0], y_offset:y_offset + img.shape[1]] = img\n",
        "\n",
        "    return padded_img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmfTKWRWH1wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_absolute_paths(directory):\n",
        "    path = pathlib.Path(directory).glob('**/*')\n",
        "    files = [x for x in path if x.is_file()]\n",
        "    return files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-59hCvYHIg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames = get_absolute_paths(\"/content/data/American/spectrograms\")\n",
        "labels = [0] * len(filenames)\n",
        "filenames += get_absolute_paths(\"/content/data/British/spectrograms\")\n",
        "labels += [1] * (len(filenames) - len(labels))\n",
        "print(len(labels), len(filenames))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spUhxfuNkm_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_model = ConvolutionalNetwork(device=\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONETClgFITQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_model.train_model(filenames, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaQmqeHZ_Zu2",
        "colab_type": "text"
      },
      "source": [
        "Copy fully trained model from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5DrDSDtvZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cp \"/content/drive/My Drive/models/resnet50.pt\" \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "206Ic7pNG5YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/resnet50.pt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL7mC3QzjJQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deep_path = \"/content/deep_copy_resnet50.pt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P_H8yhVjVb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_model.deep_save(deep_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ZQ1pDGjkd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shallow_path = \"/content/shallow_copy_resnet50.pt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd1iQ-Dyjqa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_model.save_weights(shallow_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnR2jMgUmMhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_path = \"/content/new_path_resnet50.pt\"\n",
        "torch.save(my_model.get_model().state_dict(), new_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o2WaQh_n3Q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_index = np.random.choice(range(len(filenames)), 10, replace=False)\n",
        "files = []\n",
        "for i in random_index:\n",
        "  files.append(filenames[i])\n",
        "print(files)\n",
        "preds = np.argmax(my_model.predict(files), axis=1)\n",
        "for i in range(len(files)):\n",
        "  print(preds[i], files[i])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}